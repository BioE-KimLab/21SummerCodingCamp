{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one column, return unique elements\n",
    "data = pd.read_csv('data.csv')\n",
    "target_molecules = pd.Series(data.smiles.unique())\n",
    "\n",
    "# Narrow down the database based on the condition(s)\n",
    "df = df[df.temperature > 300]\n",
    "df = df[df.some_boolean_condition]\n",
    "df = df[ (condA) & (condB)]\n",
    "\n",
    "# pick one data point based on column value condition and row index\n",
    "df[df.compound_no==50000].iloc[0]\n",
    "\n",
    "# more complicated example (multiple column value conditions, pick the first element in one column)\n",
    "data[(data.temperature == T) & (data.smiles == smi2)]['column_name'].iloc[0]\n",
    "\n",
    "# row-by-row concatenation\n",
    "results = pd.DataFrame(np.concatenate((result_train, result_valid, result_test), axis=0), \\\n",
    "                           columns = ['Predicted', 'DB', 'Temperature'])\n",
    "\n",
    "# Create new column, add data\n",
    "results['smiles'] = pd.DataFrame(list(SMILES_train) + list(SMILES_valid) + list(SMILES_test))\n",
    "results['pred-DB'] = np.abs(results['Predicted'] - results['DB'])\n",
    "results['pred-DB'].mean() #MAE\n",
    "\n",
    "# Create new column, add data by applying function to the elements in the existing column\n",
    "data['glob_feat'] = data['smiles'].apply(lambda x: glob_features(x))\n",
    "\n",
    "# pick specific rows based on the column value condition, generate new column 'X', \n",
    "# calculate new column value using other column value(s) and constants, add it to the column\n",
    "data.loc[(data.one_column == the_value_you_want),'X'] = \\\n",
    "                        np.exp(A) * (B - data['other_column'])**(C)\n",
    "\n",
    "# Dataframe to csv\n",
    "pd.DataFrame(train_valid_costs).to_csv('results_Tc/costs.csv', \\\n",
    "                                       header = ['train_cost','valid_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8:1:1 split\n",
    "target_mixtures = pd.Series(data.smiles_concat.unique())\n",
    "train = target_mixtures.sample(frac=.8, random_state=1)\n",
    "valid = target_mixtures[~target_mixtures.index.isin(train.index)].sample(frac=.5, random_state=1)\n",
    "test = target_mixtures[~target_mixtures.index.isin(train.index) & ~target_mixtures.index.isin(valid.index)]\n",
    "\n",
    "#batch shuffling in each epoch\n",
    "train_data_shuffled = train_data.sample(frac = 1.0, random_state = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple elements in a row\n",
    "for _, row in df.iterrows():\n",
    "    smi1,smi2,smi3,smi4 = row['molecule_1'], row['molecule_2'], \\\n",
    "                          row['molecule_3'], row['molecule_4']\n",
    "    #or\n",
    "    # smi1, smi2, smi3, smi4 = row[['molecule_'+str(i) for i in range(1,5)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series.describe- Count, mean, std, min, max, 25%, 50%, 75% percentiles\n",
    "pd.Series(results).describe()\n",
    "\n",
    "# list or array -> pd.Series with indices (one row in pd.DataFrame)\n",
    "pd.Series(result, index=['A', 'B', 'C'])\n",
    "\n",
    "#plot histogram for one column (pd.Series)\n",
    "df.number_of_data_points.plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nan values\n",
    "data_new['X'].dropna()\n",
    "\n",
    "#dataframe - drop rows if selected columns contain nan values\n",
    "df.dropna(subset=['column_1', 'column_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE, r2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "print(np.sqrt(mean_squared_error(result[result['Train/Valid/Test']=='Train']['DB'], \\\n",
    "                         result[result['Train/Valid/Test']=='Train']['Predicted'])))\n",
    "print(np.sqrt(mean_squared_error(result[result['Train/Valid/Test']=='Valid']['DB'], \\\n",
    "                         result[result['Train/Valid/Test']=='Valid']['Predicted'])))\n",
    "print(np.sqrt(mean_squared_error(result[result['Train/Valid/Test']=='Test']['DB'], \\\n",
    "                         result[result['Train/Valid/Test']=='Test']['Predicted'])))\n",
    "print(np.sqrt(mean_squared_error(result['DB'], \\\n",
    "                                 result['Predicted'])))\n",
    "\n",
    "print(np.sqrt(r2_score(result[result['Train/Valid/Test']=='Train']['DB'], \\\n",
    "                         result[result['Train/Valid/Test']=='Train']['Predicted'])))\n",
    "print(np.sqrt(r2_score(result[result['Train/Valid/Test']=='Valid']['DB'], \\\n",
    "                         result[result['Train/Valid/Test']=='Valid']['Predicted'])))\n",
    "print(np.sqrt(r2_score(result[result['Train/Valid/Test']=='Test']['DB'], \\\n",
    "                         result[result['Train/Valid/Test']=='Test']['Predicted'])))\n",
    "print(np.sqrt(r2_score(result['DB'], \\\n",
    "                                 result['Predicted'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby\n",
    "for _id, df in result.groupby('smiles'):\n",
    "    # df: 'sub-dataframe' whose smiles is _id\n",
    "    #do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round float values, remove duplicates\n",
    "\n",
    "df2 = df.copy(deep=True)\n",
    "#drop columns we don't need when checking duplicates\n",
    "df2 = df2.drop(['index','molecule_1','molecule_2','molecule_3','molecule_4'], axis=1)\n",
    "\n",
    "# mole fractions, temperature, pressure - 4th, 3rd, 2nd decimal\n",
    "df2 = df2.round( {'x1 [mol/mol]':4, 'x2 [mol/mol]':4, 'x3 [mol/mol]':4, 'x4 [mol/mol]':4, \\\n",
    "           'T [K]':2, 'P':3 } )\n",
    "\n",
    "#drop duplicates - we don't need to worry about data points looking like: 23.0000000000000001 \n",
    "df2_final = df2.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
